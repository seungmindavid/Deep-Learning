{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "92201eca937d417b8ebd3df4e7768418": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc18751187784c45b1ee1f8b5be7c759",
              "IPY_MODEL_2c364877fbcf4125a6d91c305070b20a",
              "IPY_MODEL_f28652b2dd7547e0860314c3742e5a15",
              "IPY_MODEL_5e4fa241189546ab8f9b626397444fc3"
            ],
            "layout": "IPY_MODEL_a38416debec84da78174a0ad9d99a068"
          }
        },
        "3155da875aaa481a8b9b247f1df58193": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bbc9c0dd6e14fb99467d7da24f77c15",
            "placeholder": "​",
            "style": "IPY_MODEL_b436001686774f06ada9d4b7441cdc28",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "00159413014d491a89dd79820dc2be4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_1bcb552a36764aba946618da1a2f8039",
            "placeholder": "​",
            "style": "IPY_MODEL_f3adab5718094086a96967a092f7c683",
            "value": ""
          }
        },
        "6cbefd3ef54745c8a243d69eca77a587": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_486ba55de63e4ad0909ade2c09a4df0d",
            "style": "IPY_MODEL_e6725a63681241c1871d8f14e9652d5f",
            "value": true
          }
        },
        "c97f6fdd9d9d426a91f712a960aa06fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_8f5cf690c9514f9faf9b66062254f11c",
            "style": "IPY_MODEL_530713d53c4e46aca8fd012ad775c264",
            "tooltip": ""
          }
        },
        "c991471511bc455091b5f1dda3967947": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f8741fc7e6544709b25eba8194d5524",
            "placeholder": "​",
            "style": "IPY_MODEL_2ecbc60ad49049b1a016c40c605fb460",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "a38416debec84da78174a0ad9d99a068": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "4bbc9c0dd6e14fb99467d7da24f77c15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b436001686774f06ada9d4b7441cdc28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bcb552a36764aba946618da1a2f8039": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3adab5718094086a96967a092f7c683": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "486ba55de63e4ad0909ade2c09a4df0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6725a63681241c1871d8f14e9652d5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f5cf690c9514f9faf9b66062254f11c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "530713d53c4e46aca8fd012ad775c264": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "1f8741fc7e6544709b25eba8194d5524": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ecbc60ad49049b1a016c40c605fb460": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "805f2049d1d64fdab090bc3031a26eff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98a9717028f34aa4af11770429eb5f02",
            "placeholder": "​",
            "style": "IPY_MODEL_a2408355eb4d445c9f72246865236c92",
            "value": "Connecting..."
          }
        },
        "98a9717028f34aa4af11770429eb5f02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2408355eb4d445c9f72246865236c92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc18751187784c45b1ee1f8b5be7c759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e051163d3b04974bd916a66aed03ca9",
            "placeholder": "​",
            "style": "IPY_MODEL_45aaced67e0440749c9da1fa9d202ecf",
            "value": "Token is valid (permission: write)."
          }
        },
        "2c364877fbcf4125a6d91c305070b20a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a09f41551cdb4e2fb3e25ce1b8b981e5",
            "placeholder": "​",
            "style": "IPY_MODEL_7d1f736b81664692b5c4eb6a009d078e",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "f28652b2dd7547e0860314c3742e5a15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46a0d48623024d40b13098e9134fa4fd",
            "placeholder": "​",
            "style": "IPY_MODEL_9dc18a26ae0542c8955c078289947579",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "5e4fa241189546ab8f9b626397444fc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ab68c90fcc44adda56a10b31ac6b98e",
            "placeholder": "​",
            "style": "IPY_MODEL_8b93317f9ff641bd88d91ad74c7625a5",
            "value": "Login successful"
          }
        },
        "3e051163d3b04974bd916a66aed03ca9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45aaced67e0440749c9da1fa9d202ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a09f41551cdb4e2fb3e25ce1b8b981e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d1f736b81664692b5c4eb6a009d078e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46a0d48623024d40b13098e9134fa4fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dc18a26ae0542c8955c078289947579": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ab68c90fcc44adda56a10b31ac6b98e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b93317f9ff641bd88d91ad74c7625a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TOXIC DETECTOR"
      ],
      "metadata": {
        "id": "UUoVF1psTD05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "# Deep Learning\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "\n",
        "# General\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Device Setting\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda:0\")\n",
        "  print(\"GPU\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "  print(\"CPU\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8A5cNF6zJZBv",
        "outputId": "6ddc3d5a-1ba8-400d-8002-5be2c2f81e6d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Tokenizer from huggingface\n"
      ],
      "metadata": {
        "id": "cHWVnpqfS8ac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "92201eca937d417b8ebd3df4e7768418",
            "3155da875aaa481a8b9b247f1df58193",
            "00159413014d491a89dd79820dc2be4a",
            "6cbefd3ef54745c8a243d69eca77a587",
            "c97f6fdd9d9d426a91f712a960aa06fe",
            "c991471511bc455091b5f1dda3967947",
            "a38416debec84da78174a0ad9d99a068",
            "4bbc9c0dd6e14fb99467d7da24f77c15",
            "b436001686774f06ada9d4b7441cdc28",
            "1bcb552a36764aba946618da1a2f8039",
            "f3adab5718094086a96967a092f7c683",
            "486ba55de63e4ad0909ade2c09a4df0d",
            "e6725a63681241c1871d8f14e9652d5f",
            "8f5cf690c9514f9faf9b66062254f11c",
            "530713d53c4e46aca8fd012ad775c264",
            "1f8741fc7e6544709b25eba8194d5524",
            "2ecbc60ad49049b1a016c40c605fb460",
            "805f2049d1d64fdab090bc3031a26eff",
            "98a9717028f34aa4af11770429eb5f02",
            "a2408355eb4d445c9f72246865236c92",
            "bc18751187784c45b1ee1f8b5be7c759",
            "2c364877fbcf4125a6d91c305070b20a",
            "f28652b2dd7547e0860314c3742e5a15",
            "5e4fa241189546ab8f9b626397444fc3",
            "3e051163d3b04974bd916a66aed03ca9",
            "45aaced67e0440749c9da1fa9d202ecf",
            "a09f41551cdb4e2fb3e25ce1b8b981e5",
            "7d1f736b81664692b5c4eb6a009d078e",
            "46a0d48623024d40b13098e9134fa4fd",
            "9dc18a26ae0542c8955c078289947579",
            "3ab68c90fcc44adda56a10b31ac6b98e",
            "8b93317f9ff641bd88d91ad74c7625a5"
          ]
        },
        "id": "k2fr3hy4THcE",
        "outputId": "d981bf32-a4ae-4021-8565-5926b7bd9c61"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "92201eca937d417b8ebd3df4e7768418"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets tokenizers\n",
        "\n",
        "# Huggingface\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordLevel\n",
        "from tokenizers.trainers import WordLevelTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from transformers import BertTokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H38vWV5OcHBA",
        "outputId": "3d420c9d-4062-4a8b-ca82-0d64070dd5d0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/510.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/510.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.15.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.18.0 dill-0.3.8 multiprocess-0.70.16 xxhash-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration"
      ],
      "metadata": {
        "id": "lJvaf4g2YgPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_config(num_epochs):\n",
        "  return{\n",
        "      \"train_batch_size\": 8,\n",
        "      \"test_batch_size\": 1,\n",
        "      \"num_epochs\": num_epochs,\n",
        "      \"lr\": 3e-4,\n",
        "      \"seq_len\": 256,\n",
        "      \"d_model\": 256,\n",
        "      \"h\": 4,\n",
        "      \"depth\" : 2,\n",
        "      \"dropout\": 0.2,\n",
        "      \"num_classes\": 2,\n",
        "      \"checkpoint\": 'bert-base-uncased'\n",
        "  }\n",
        "\n"
      ],
      "metadata": {
        "id": "VpRd-xq7Ym0w"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data\n",
        "1. Kaggle: jigsaw-toxic-comment-classification-challenge\n",
        "\n"
      ],
      "metadata": {
        "id": "DXST_hhDFzDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content'\n",
        "os.chmod('/content/kaggle.json', 600)\n",
        "\n",
        "!kaggle competitions download -c jigsaw-toxic-comment-classification-challenge\n",
        "!unzip jigsaw-toxic-comment-classification-challenge.zip\n",
        "!unzip test.csv.zip\n",
        "!unzip train.csv.zip\n",
        "!unzip test_labels.csv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naTOveLR5iLn",
        "outputId": "4bfd62de-a24f-40bc-f960-80c8a7f02744"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading jigsaw-toxic-comment-classification-challenge.zip to /content\n",
            " 76% 40.0M/52.6M [00:00<00:00, 129MB/s] \n",
            "100% 52.6M/52.6M [00:00<00:00, 120MB/s]\n",
            "Archive:  jigsaw-toxic-comment-classification-challenge.zip\n",
            "  inflating: sample_submission.csv.zip  \n",
            "  inflating: test.csv.zip            \n",
            "  inflating: test_labels.csv.zip     \n",
            "  inflating: train.csv.zip           \n",
            "Archive:  test.csv.zip\n",
            "  inflating: test.csv                \n",
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n",
            "Archive:  test_labels.csv.zip\n",
            "  inflating: test_labels.csv         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "test_labels = pd.read_csv('test_labels.csv')\n",
        "\n",
        "print(f\"Toxic rate:\\n{train['toxic'].value_counts(normalize=True)}\\n\")\n",
        "print(f\"Toxic rate:\\n{train['severe_toxic'].value_counts(normalize=True)}\\n\")\n",
        "print(f\"Toxic rate:\\n{train['obscene'].value_counts(normalize=True)}\\n\")\n",
        "print(f\"Toxic rate:\\n{train['threat'].value_counts(normalize=True)}\\n\")\n",
        "print(f\"Toxic rate:\\n{train['insult'].value_counts(normalize=True)}\\n\")\n",
        "print(f\"Toxic rate:\\n{train['identity_hate'].value_counts(normalize=True)}\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WcFocOp8LbV",
        "outputId": "99efa9be-2490-44ad-d7cd-45f62edd457f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Toxic rate:\n",
            "toxic\n",
            "0    0.904156\n",
            "1    0.095844\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Toxic rate:\n",
            "severe_toxic\n",
            "0    0.990004\n",
            "1    0.009996\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Toxic rate:\n",
            "obscene\n",
            "0    0.947052\n",
            "1    0.052948\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Toxic rate:\n",
            "threat\n",
            "0    0.997004\n",
            "1    0.002996\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Toxic rate:\n",
            "insult\n",
            "0    0.950636\n",
            "1    0.049364\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Toxic rate:\n",
            "identity_hate\n",
            "0    0.991195\n",
            "1    0.008805\n",
            "Name: proportion, dtype: float64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Balancing & Split into train, val"
      ],
      "metadata": {
        "id": "hP2cReK94mSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = pd.read_csv('train.csv')\n",
        "\n",
        "non_toxic = data[data['toxic']==0]\n",
        "toxic = data[(data['severe_toxic'] == 1) | (data['obscene'] == 1) | (data['threat'] == 1)| (data['insult'] == 1)| (data['identity_hate'] == 1)]\n",
        "\n",
        "print(f\"# of non toxic data: {len(non_toxic)}, \\n# of toxic data: {len(toxic)}\\n\")\n",
        "\n",
        "non_toxic = resample(non_toxic,\n",
        "                     replace=False,\n",
        "                     n_samples=len(toxic) * 2,\n",
        "                     random_state=123)\n",
        "\n",
        "dataset = pd.concat([toxic, non_toxic])\n",
        "X = dataset['comment_text']\n",
        "y = dataset['toxic']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(y_train.value_counts(normalize=True))\n",
        "print(y_test.value_counts(normalize=True))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0V5eT_ybaTlK",
        "outputId": "8aa92b43-7b49-4f8b-a604-64238bb2e70b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of non toxic data: 144277, \n",
            "# of toxic data: 10559\n",
            "\n",
            "toxic\n",
            "0    0.695829\n",
            "1    0.304171\n",
            "Name: proportion, dtype: float64\n",
            "toxic\n",
            "0    0.69697\n",
            "1    0.30303\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# toxic.head()\n",
        "# header = [\"comment_text\"]\n",
        "# toxic.to_csv('toxic.csv', columns = header, index=False)"
      ],
      "metadata": {
        "id": "-buy0S_15U2g"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizer examples"
      ],
      "metadata": {
        "id": "dB-tr52JcVTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "vocab_size = tokenizer.vocab_size\n",
        "config = get_config(10)\n",
        "print(f'Pre-trained Tokenizer below: \\n {tokenizer}')\n",
        "\n",
        "texts = list(X_train.values[:5])\n",
        "encoded_inputs = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
        "input_ids = encoded_inputs['input_ids']\n",
        "token_type_ids = encoded_inputs['token_type_ids']\n",
        "attention_mask = encoded_inputs['attention_mask']\n",
        "print(f'Input Ids: {input_ids}')\n",
        "print(f'Token type Ids: {token_type_ids}')\n",
        "print(f'Attention masks: {attention_mask}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WH-Ce2Ya5_5",
        "outputId": "8bc7c025-effa-4db5-81a0-f6413ef98a60"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-trained Tokenizer below: \n",
            " BertTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
            "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "}\n",
            "Input Ids: tensor([[  101,  7592,  1010,  1045,  2134,  1005,  1056,  3972, 12870,  2009,\n",
            "          1010,  2019,  4748, 10020,  2106,  1010,  1045,  1005,  1049,  2025,\n",
            "          2019,  4748, 10020,  1012,  2021,  2145,  1010,  1996,  3720, 14424,\n",
            "          1037,  3232,  1997,  1996, 16948,  6043,  1010,  4067,  2017,  1012,\n",
            "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0],\n",
            "        [  101,  6616,  2017,  2017,  2643,  4365,  2388,  6616,  2378,  2365,\n",
            "          1997,  1037,  7743,  2644,  2108,  1037,  5236,  4632,  4485,  4974,\n",
            "          1998,  2022,  6616,  2378,  4658,  2005,  2320,   102,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0],\n",
            "        [  101,  2009,  2001,  2036,  2170,  1005,  1996,  2103,  1998,  2221,\n",
            "          1997,  7067,  1005,  2043,  1045,  2973,  2045,  1999,  3359,  1010,\n",
            "          1998,  2023,  2001,  1996,  3793,  2006,  1996,  6192,  4925, 23773,\n",
            "          2015,  2004,  2017,  3133,  7067,  1012,  2023,  8224,  3945, 11618,\n",
            "          2039,  3243,  1037,  2261,  7604,  2000,  1996,  2516,  1012,  1011,\n",
            "          3983,  2281,  2494,   102],\n",
            "        [  101,  2644, 25672,  2075, 11476, 10086,  2015,   999,  2009,  2003,\n",
            "          1037,  2755,  2008, 14089,  5416,  2072,  2003,  9217,  1996,  2097,\n",
            "          1997,  1996,  7206,  1997,  3516,  1010,  2017,  3538,  1997,  4485,\n",
            "           999,  2644,  7065,  9355, 11476, 10086,  2015,  2138,  1997,  2115,\n",
            "          2576, 13827,   999,   102,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0],\n",
            "        [  101,  2054,  1996, 19556, 12043,  2682,  2056,  3632,  3313,  2005,\n",
            "          2033,  1012,  6616,  2545,  1012,   102,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0]])\n",
            "Token type Ids: tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0]])\n",
            "Attention masks: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Dataset"
      ],
      "metadata": {
        "id": "AffiHV6pY5CB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class BERTDataset(Dataset):\n",
        "  def __init__(self, text, toxic, config):\n",
        "    super().__init__()\n",
        "\n",
        "    self.txt = text.values\n",
        "    self.y = toxic.values\n",
        "\n",
        "    self.seq_len = config['seq_len']\n",
        "    self.h = config['h']\n",
        "    self.tokenizer = BertTokenizer.from_pretrained(config['checkpoint'])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.txt)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    source = str(self.txt[idx])\n",
        "    target = self.y[idx]\n",
        "\n",
        "    h = self.h\n",
        "    seq_len = self.seq_len\n",
        "\n",
        "    # tokenized_source\n",
        "    tokenized_source = self.tokenizer(source,\n",
        "                                     max_length = self.seq_len,\n",
        "                                     padding='max_length',\n",
        "                                     truncation = True\n",
        "                                     )\n",
        "\n",
        "    encoder_input = torch.tensor(tokenized_source['input_ids'], dtype= torch.long)\n",
        "\n",
        "    # mask\n",
        "    encoder_mask = torch.tensor(tokenized_source['attention_mask'], dtype= torch.long).unsqueeze(0)\n",
        "    encoder_mask = encoder_mask.repeat(1, h, 1)\n",
        "    encoder_mask = encoder_mask.expand(seq_len, h, seq_len)\n",
        "    encoder_mask = encoder_mask.transpose(0,1).contiguous()\n",
        "\n",
        "    item = {\n",
        "          'txt': source,\n",
        "          'encoder_input': encoder_input,\n",
        "          'encoder_mask': encoder_mask,\n",
        "          'target': target\n",
        "    }\n",
        "\n",
        "    return item"
      ],
      "metadata": {
        "id": "7x6qdHO2Y4ms"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataLoader"
      ],
      "metadata": {
        "id": "Vrrnt7IvkFgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_loader = DataLoader(\n",
        "    BERTDataset(X_train, y_train, config),\n",
        "    batch_size = config['train_batch_size'],\n",
        "    shuffle=True,\n",
        "    pin_memory = True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    BERTDataset(X_test, y_test, config),\n",
        "    batch_size = config['test_batch_size'],\n",
        "    shuffle=True,\n",
        "    pin_memory = True\n",
        ")\n",
        "\n",
        "dataiter = iter(train_loader)\n",
        "batch = next(dataiter)\n",
        "for idx in range(len(batch['encoder_input'])):\n",
        "  print(f\"encoder_input: {batch['encoder_input'][idx]}\")\n",
        "  print(f\"encoder_mask: {batch['encoder_mask'][idx].size()}\")\n",
        "  print(f\"target: {batch['target'][idx]}\")\n",
        "\n",
        "dataiter = iter(test_loader)\n",
        "batch = next(dataiter)\n",
        "for idx in range(len(batch['encoder_input'])):\n",
        "  print(f\"encoder_input: {batch['encoder_input'][idx]}\")\n",
        "  print(f\"encoder_mask: {batch['encoder_mask'][idx].size()}\")\n",
        "  print(f\"target: {batch['target'][idx]}\")"
      ],
      "metadata": {
        "id": "YZbq86z1FqrV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6673a27a-0057-4f2b-a46b-96e0b1a6ec7b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder_input: tensor([  101,  1000,  2045,  2003,  2053,  4957,  2000, 11980,  9499,  1999,\n",
            "         4239,  8026,  3619,  1005,  3720,  1012,  2045,  1005,  1055,  1037,\n",
            "         4957,  2000, 11980,  2916,  1999,  3159,  3487,  2479,  1010,  2021,\n",
            "         2008,  1005,  1055,  1037, 11476,  8476, 10462,  3584,  2013,  2010,\n",
            "         9927,  1012,  1045,  7868,  2008,  2043,  1996,  2874,  2001,  2631,\n",
            "         1999,  7612,  1010,  2045,  2001,  2012,  2560,  2028,  2711,  2007,\n",
            "         2070,  2433,  1997,  1037, 11980,  1010,  1998,  2061,  2013,  2059,\n",
            "         2006,  2000,  2294,  2030,  7188,  1010,  1996,  8476,  2003, 15142,\n",
            "         2000,  2720,  1012,  6986,  2063,  1005,  1055, 27776, 15265,  7716,\n",
            "        11636,  5761,  1012,  1045,  1005,  2310,  3718,  1996,  2156,  2036,\n",
            "         4957,  1010,  2021,  1996,  2616,  1000,  1000,  2000, 16422,  2007,\n",
            "        13597,  1000,  1000,  2085,  2391,  2000,  2023,  3720,  1012,  2748,\n",
            "         1010,  1045,  2079, 19148,  2008,  2009,  1005,  1055,  2035,  1037,\n",
            "         2028,  1011,  2158,  3169,  1012,  1045,  1005,  2310,  8385,  8781,\n",
            "         2032,  2006,  1996,  8476,  1010,  2007,  2053,  3433,  4728,  1012,\n",
            "         4953, 15413,  1010,  7773,  1010,  5020,  6648,  1010,  4385,  1012,\n",
            "         1010,  2748,  1010,  1045,  5993,  1996,  3720,  2003, 14699,  2135,\n",
            "        11158,  2302,  2023,  4180,  1010,  2029,  4415,  2038,  2042,  1997,\n",
            "         5197,  2000,  1996,  2874,  2058,  2010,  3408,  1999,  2436,  1012,\n",
            "         1045, 13260,  2017,  2000,  5587,  2009,  2000,  1996,  3720,  1010,\n",
            "         1998,  4957,  2000,  2739,  6325,  1997,  2122,  9849,  1010,  2061,\n",
            "         2111,  2064,  3191,  2055,  2068,  1999,  2582,  5995,  1012,  2498,\n",
            "         2038,  2412,  3030,  2017,  2030,  3087,  2842,  2013,  5815,  2023,\n",
            "         4180,  2000,  1996,  3720,  1012,  2035,  2057,  3198,  2003,  2008,\n",
            "         2673,  2003,  7919, 14964,  1998,  3397,  2053, 13433,  2615,  1012,\n",
            "         1000,   102,     0,     0,     0,     0])\n",
            "encoder_mask: torch.Size([4, 256, 256])\n",
            "target: 0\n",
            "encoder_input: tensor([  101,  1996,  8645,  5484,  1040, 12521,  3475,  1005,  1056,  3214,\n",
            "         2004,  1037, 15620,  2009,  2003,  3214,  2004,  1037,  7570, 14760,\n",
            "         3351,  2000,  1996, 27057,  1011,  2000,  1011,  3000,  8320,  1012,\n",
            "         2045, 29278,  2009,  2003,  1037,  1006,  8320,  1007,  4368,  2482,\n",
            "         1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "encoder_mask: torch.Size([4, 256, 256])\n",
            "target: 0\n",
            "encoder_input: tensor([  101,  5310,  1024,  2073,  1013, 18712,  7630,  1045,  5060,  2017,\n",
            "         1005,  2310,  3653,  1011,  7861, 24971,  2135,  4222, 18712,  7630,\n",
            "         2005,  4748, 21266,  5605,  1012,  2052,  2017,  2568,  2065,  1045,\n",
            "         2522,  1011,  4222,  1029,  3531, 10373,  2004,  2092,  1045,  1005,\n",
            "         2222,  2022,  2041,  1997,  2237,  1999,  1037,  3204,  1999,  2055,\n",
            "         2702,  2847,  2030,  2061,  1998,  2089,  2025,  2156,  1037,  2831,\n",
            "         4471,  1012,  4283,  1012,   102,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "encoder_mask: torch.Size([4, 256, 256])\n",
            "target: 0\n",
            "encoder_input: tensor([  101,  2085,  2144,  1045,  2572,  2067,  2044,  2108,  7917,  2005,\n",
            "         5986,  2847,  1010,  1045,  2205,  2215,  2000,  2695,  2006,  2122,\n",
            "         2200,  3210,  1010,  2138,  1045,  2031,  2042,  3395,  2000, 16962,\n",
            "         6776,  2386,  1005,  1055, 14652,  1998, 13593,  9164,  1012, 16962,\n",
            "         6776,  5804,  1010,  2017,  2097,  2663, 13986,  2006, 16948,  2065,\n",
            "         2017,  3582,  2122,  8128,  1011,  1015,  1007,  2065,  2017,  2079,\n",
            "         2025,  3972, 12870,  2060,  2111,  1005,  1055,  8466,  1998,  2079,\n",
            "         2025, 13590,  5433,  1997,  2831,  1011,  5530,  1999,  2344,  2000,\n",
            "        29454, 10421,  1037,  6594,  1012,  2023,  2003, 24282,  9164,  1998,\n",
            "         1045,  1005,  1049,  2469,  2008,  2017,  2024,  2012,  2560,  1997,\n",
            "         6830,  2287,  1012,  1016,  1007,  5138,  2115, 12051, 11210,  1998,\n",
            "         7188, 12711,  1010,  2612,  1997, 14205,  2135,  4748, 22658,  2000,\n",
            "         2068,  1012,  2009,  2097,  2069,  3426,  2017,  2582,  7861, 20709,\n",
            "         4757,  3672,  1012,  1017,  1007,  2079,  2025,  2677, 21078,  2043,\n",
            "         2500,  2391,  2041,  2115,  3768,  1997,  3716,  1012, 19080,  5138,\n",
            "         2115, 12051,  1998,  3046,  2000,  3362,  2005,  1037, 12014,  1012,\n",
            "         1018,  1007,  2079,  2025,  2022, 14205,  1998, 12170,  9102,  2058,\n",
            "         2235,  3314,  1012,  1999,  2460,  1010,  2022, 26270,  2389,  1012,\n",
            "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "encoder_mask: torch.Size([4, 256, 256])\n",
            "target: 0\n",
            "encoder_input: tensor([  101,  6960,  2591, 14048,  2096,  1045,  2079, 21090,  2007,  1996,\n",
            "        26203,  3972, 20624,  2239,  1997,  1996,  3720,  1010,  1045,  2036,\n",
            "         5441,  2008,  2009,  2052,  2025,  2197,  2936,  2084,  1037,  2733,\n",
            "         2006, 16948,  1012,  1996,  3291,  2003,  2008,  2009,  3544,  2000,\n",
            "         2022,  2434,  2470,  1024,  2738,  2084,  2019,  7526,  1997,  9686,\n",
            "         2078,  2241,  2006,  2405, 15182,  1998,  4391,  1010,  2009, 16473,\n",
            "         2006,  4784,  2013,  2536,  4216,  1998, 24203,  2229, 10057,  2068,\n",
            "         1999,  2434,  3971,  1012,  2065,  1996,  3720,  2020, 29414,  1010,\n",
            "         2009,  2052,  2855,  2022,  4222,  2005,  3972, 20624,  2239,  1010,\n",
            "         1998,  1045,  2052,  6118, 16755,  3972, 20624,  2239,  2005,  1996,\n",
            "         4436,  1045,  3855,  2682,  1012,  1045,  2052,  6592,  2017,  2556,\n",
            "         1996,  2053,  2434,  2470,  5009,  4179,  2000,  2115,  2934,  1998,\n",
            "         4863,  2008,  2045,  2024,  6537,  2006,  2054,  2017,  2064, 10172,\n",
            "         2000, 16948,  1025,  2002,  2323,  2022,  2583,  2000,  2424,  2019,\n",
            "         6585,  6891,  2005,  2017,  2000, 10172,  2115,  9556,  1012,  1045,\n",
            "         2052,  2036,  6592,  2008,  2002,  3191, 16948,  1024,  2082,  1998,\n",
            "         2118,  3934,  1012,  2065,  2002,  2038,  2582,  3980,  1010,  2002,\n",
            "         2064,  8833,  1999,  1013,  3443,  2019,  4070,  1998,  3198,  3081,\n",
            "         1996,  1063,  1063,  2393,  4168,  1065,  1065, 23561,  1012,  1517,\n",
            "         1005,  1005,  1005,  1005,  1005,  1005,  1006,  2831,  1007,   102,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "encoder_mask: torch.Size([4, 256, 256])\n",
            "target: 0\n",
            "encoder_input: tensor([  101,  2092,  1010,  2823,  2111,  7166,  2000,  5293,  2008,  2023,\n",
            "         2173,  2003,  2019, 12204,  1010,  2025,  1037, 13761,  2609,  1012,\n",
            "         6972,  2003,  2028,  1997,  2026,  5440,  8320, 24438,  1998,  1045,\n",
            "         2428,  3246,  2002,  1005,  1055,  2145,  4142,  1012,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "encoder_mask: torch.Size([4, 256, 256])\n",
            "target: 0\n",
            "encoder_input: tensor([  101, 10958, 10270,  2595,  2003,  8038,  2290,  1012,  2002,  2003,\n",
            "         1996,  8038, 13871,  4355,  2388,  2075,  5413, 11602, 12043,  1999,\n",
            "         1996,  2088,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "encoder_mask: torch.Size([4, 256, 256])\n",
            "target: 1\n",
            "encoder_input: tensor([  101,  2035, 15536, 21128,  5991,  5310,  2624, 12325,  8534,  2013,\n",
            "         9260,  2006,  2035, 15536, 14270,  1010,  2064,  2017,  4895, 23467,\n",
            "         2033,  1012,  1045,  2123,  1005,  1056,  2215,  2000,  3524,  2385,\n",
            "         2420,  1010,  4229,  2549,  2847,  2000, 10086,  2153,  1010,  2008,\n",
            "         1005,  1055,  1037,  2146,  2051,  1998,  1045,  2215,  2000, 10086,\n",
            "         2006,  2026, 15536,  3211,  2153,  1010,  3638,  7160, 15536,  3211,\n",
            "         1012,  5818,  1012, 23593,  1012,  7287,  1012, 18561,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "encoder_mask: torch.Size([4, 256, 256])\n",
            "target: 0\n",
            "encoder_input: tensor([  101,  2492,  2817,  1010, 12233,  2054,  2828,  1997,  9986,  2024,\n",
            "         2017,  1029,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "encoder_mask: torch.Size([4, 256, 256])\n",
            "target: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ready to build Transformer\n",
        "For Toxic classification, we only need encoder blocks.\n",
        "\n",
        "1. Input Embedding\n",
        "2. Positional Encoding\n",
        "3. Feed Forward\n",
        "4. Multi-Head Attention\n",
        "5. Encoder block\n",
        "6. Transformer\n"
      ],
      "metadata": {
        "id": "fGYsTVjPFO1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Input Embedding + Positional Encoding"
      ],
      "metadata": {
        "id": "Hht2a7VfKQPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "class InputEmbedding(nn.Module):\n",
        "  def __init__(self, vocab_size, d_model):\n",
        "    super().__init__()\n",
        "    self.vocab_size = vocab_size\n",
        "    self.d_model = d_model\n",
        "    self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.embedding(x) * (self.d_model ** 0.5)\n",
        "\n",
        "\n",
        "class PositionalEmbedding(nn.Module):\n",
        "  def __init__(self, d_model, seq_len):\n",
        "    super().__init__()\n",
        "\n",
        "    pe = torch.zeros(seq_len, d_model)\n",
        "\n",
        "    pos = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1)\n",
        "    div = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000) / d_model))\n",
        "\n",
        "    pe[:, 0::2] = torch.sin(pos*div)\n",
        "    pe[:, 1::2] = torch.cos(pos*div)\n",
        "    pe = pe.unsqueeze(0)\n",
        "    self.register_buffer('pe', pe)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x + self.pe[:, :x.shape[1], :].requires_grad_(False)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "qeolerlLiFk_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Input Embedding + Positional Embedding Example"
      ],
      "metadata": {
        "id": "NtdLCitVKGKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(config['checkpoint'])\n",
        "print(tokenizer)\n",
        "\n",
        "input_embedding = InputEmbedding(tokenizer.vocab_size, config['d_model'])\n",
        "positional_encoding = PositionalEmbedding(config['d_model'], config['seq_len'])\n",
        "\n",
        "train_ds = BERTDataset(X_train, y_train, config)\n",
        "data = train_ds.__getitem__(1)\n",
        "\n",
        "encoder_input = data['encoder_input']\n",
        "print(f\"Source ids: {encoder_input}\")\n",
        "print(f\"Source ids size: {encoder_input.size()}\")\n",
        "\n",
        "src_emb = input_embedding(encoder_input.unsqueeze(0))\n",
        "print(f\"\\nSource after embedded size: {src_emb.size()}\")\n",
        "src_pe = positional_encoding(src_emb)\n",
        "print(f\"Source after positional embedded size: {src_pe.size()}\\n\")\n",
        "print(f\"Source after positional embedding: {src_pe}\\n\")\n",
        "\n",
        "val_ds = BERTDataset(X_test, y_test, config)\n",
        "data = val_ds.__getitem__(1)\n",
        "\n",
        "encoder_input = data['encoder_input']\n",
        "print(f\"Source ids: {encoder_input}\")\n",
        "print(f\"Source ids size: {encoder_input.size()}\")\n",
        "\n",
        "src_emb = input_embedding(encoder_input.unsqueeze(0))\n",
        "print(f\"\\nSource after embedded size: {src_emb.size()}\")\n",
        "src_pe = positional_encoding(src_emb)\n",
        "print(f\"Source after positional embedded size: {src_pe.size()}\\n\")\n",
        "print(f\"Source after positional embedding: {src_pe}\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSm1SzRYnn3O",
        "outputId": "9db23d1b-b474-40f5-fc14-240e76af12d0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
            "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "}\n",
            "Source ids: tensor([ 101, 6616, 2017, 2017, 2643, 4365, 2388, 6616, 2378, 2365, 1997, 1037,\n",
            "        7743, 2644, 2108, 1037, 5236, 4632, 4485, 4974, 1998, 2022, 6616, 2378,\n",
            "        4658, 2005, 2320,  102,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0])\n",
            "Source ids size: torch.Size([256])\n",
            "\n",
            "Source after embedded size: torch.Size([1, 256, 256])\n",
            "Source after positional embedded size: torch.Size([1, 256, 256])\n",
            "\n",
            "Source after positional embedding: tensor([[[  6.5779,   6.7838,   5.1001,  ...,   1.5206,   2.8501, -18.5249],\n",
            "         [  4.6334, -31.8048,  11.0517,  ...,  28.0606,  -7.0972, -27.5489],\n",
            "         [ 12.2872, -22.6145,  -0.6033,  ...,  34.0102,  -4.1708,  30.6117],\n",
            "         ...,\n",
            "         [ 10.1377,  -9.1547, -30.0267,  ..., -32.3634,  -4.8191,  -9.7760],\n",
            "         [  9.5948,  -9.9451, -30.8890,  ..., -32.3634,  -4.8190,  -9.7760],\n",
            "         [  8.6365,  -9.9154, -31.2048,  ..., -32.3634,  -4.8189,  -9.7760]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "\n",
            "Source ids: tensor([  101,  2123,  1005,  1056,  2022,  2019,  4632,  1012,  2009,  2001,\n",
            "         1037,  3154, 10086,  4736,  1012,  1998,  2073,  2031,  1045,  1037,\n",
            "         1038, 14277, 11371,  1029,  5585,  1012, 15471,  1012, 22343,  1012,\n",
            "        11502,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "Source ids size: torch.Size([256])\n",
            "\n",
            "Source after embedded size: torch.Size([1, 256, 256])\n",
            "Source after positional embedded size: torch.Size([1, 256, 256])\n",
            "\n",
            "Source after positional embedding: tensor([[[  6.5779,   6.7838,   5.1001,  ...,   1.5206,   2.8501, -18.5249],\n",
            "         [ -3.2507, -14.7781,  23.0680,  ...,  21.0131,   5.0240,  25.2707],\n",
            "         [-14.1833,   9.4150, -21.2084,  ...,   2.5404, -15.8480, -13.4756],\n",
            "         ...,\n",
            "         [ 10.1377,  -9.1547, -30.0267,  ..., -32.3634,  -4.8191,  -9.7760],\n",
            "         [  9.5948,  -9.9451, -30.8890,  ..., -32.3634,  -4.8190,  -9.7760],\n",
            "         [  8.6365,  -9.9154, -31.2048,  ..., -32.3634,  -4.8189,  -9.7760]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feed Forward\n",
        "- Following \"Attention is all you need\", we need each of the layers in encoder and decoder to contain a fully connected feed-forward network, which is applied to each position separately and identically. It consists of two linear transformations with a ReLU activation in between.\n",
        "\n",
        "$FFN(x) = max(0, xW_1 + b_1)W_2 + b_2$\n",
        "\n",
        "- $d_{model} = 256$, and the inner-layer has dimensionality $d_{ff} = d_{model} * 4$"
      ],
      "metadata": {
        "id": "vDUx8mcbKPDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.d_model = config['d_model']\n",
        "    self.d_ff = self.d_model * 4\n",
        "\n",
        "    self.ffn = nn.Sequential(\n",
        "        nn.Linear(self.d_model, self.d_ff),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(self.d_ff, self.d_model),\n",
        "        nn.Dropout(config['dropout'])\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.ffn(x)\n"
      ],
      "metadata": {
        "id": "EBbr-r4mH9K4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-Head Attention"
      ],
      "metadata": {
        "id": "15KJWDDvSSng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "\n",
        "    self.d_model = config['d_model']\n",
        "    self.h = config['h']\n",
        "\n",
        "    assert self.d_model % self.h == 0, \"d_model must be divisible by h\"\n",
        "\n",
        "\n",
        "    self.d_k = self.d_model // self.h\n",
        "    # Query, key, value\n",
        "    self.W_q = nn.Linear(self.d_model, self.d_model, bias=False)\n",
        "    self.W_k = nn.Linear(self.d_model, self.d_model, bias=False)\n",
        "    self.W_v = nn.Linear(self.d_model, self.d_model, bias=False)\n",
        "\n",
        "    # Last Layer\n",
        "    self.W_o = nn.Linear(self.d_model, self.d_model, bias=False)\n",
        "\n",
        "    # dropout\n",
        "    self.dropout = nn.Dropout(config['dropout'])\n",
        "\n",
        "  def forward(self, q, k, v, mask):\n",
        "    # input size: torch.Size([B, seq_len, d_model])\n",
        "    B, Seq_len, d_model = q.size()\n",
        "\n",
        "    h = self.h\n",
        "    d_k = self.d_k\n",
        "    d_model = self.d_model\n",
        "\n",
        "    query = self.W_q(q)\n",
        "    key = self.W_k(k)\n",
        "    value = self.W_v(v)\n",
        "\n",
        "    # size: (Batch, Seq_len, d_model) -> (Batch, Seq_len, h, d_model // h)\n",
        "    query = query.view(B, Seq_len, h, d_k)\n",
        "    key = key.view(B, Seq_len, h, d_k)\n",
        "    value = value.view(B, Seq_len, h, d_k)\n",
        "\n",
        "    # (Batch, Seq_len, h, d_k) -> (Batch, h, Seq_len, d_k)\n",
        "    # (Batch, h, Seq_len, d_k) -> (Batch * h, Seq_len, d_k)\n",
        "    query = query.transpose(1,2).contiguous().view(B * h, Seq_len, d_k)\n",
        "    key = key.transpose(1,2).contiguous().view(B * h, Seq_len, d_k)\n",
        "    value = value.transpose(1,2).contiguous().view(B * h, Seq_len, d_k)\n",
        "\n",
        "    # paying attention to each sequences, therefore size should be (Batch *h, Seq_len, Seq_len)\n",
        "    W = query @ key.transpose(1,2)\n",
        "    W = W / (d_model ** 0.5)\n",
        "\n",
        "    if mask is not None:\n",
        "      mask = mask.view(B * h, Seq_len, Seq_len)\n",
        "      W = W.masked_fill(mask == 0, float(\"-inf\"))\n",
        "\n",
        "    W = W.softmax(dim = -1)\n",
        "    # drop out\n",
        "    W = self.dropout(W)\n",
        "\n",
        "    out = W @ value # (B * h, seq_len, d_k)\n",
        "    out = out.view(B, h, Seq_len, d_k)\n",
        "    out = out.transpose(1,2).contiguous().view(B, Seq_len, h * d_k)\n",
        "    return self.W_o(out)\n"
      ],
      "metadata": {
        "id": "bG7bb3JDLPIE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder Block"
      ],
      "metadata": {
        "id": "lTcgDNhvXlfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super(EncoderBlock, self).__init__()\n",
        "\n",
        "    self.d_model = config['d_model']\n",
        "\n",
        "    self.MultiHeadAttention = MultiHeadAttention(config)\n",
        "    self.ln_1 = nn.LayerNorm(self.d_model)\n",
        "    self.ln_2 = nn.LayerNorm(self.d_model)\n",
        "    self.FeedForward = FeedForward(config)\n",
        "\n",
        "  def forward(self, x, mask):\n",
        "    x = x + self.MultiHeadAttention(x, x, x, mask)\n",
        "    x = self.ln_1(x)\n",
        "    x = x + self.FeedForward(x)\n",
        "    x = self.ln_2(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "LEfUaAyyXjYw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Toxic Detector"
      ],
      "metadata": {
        "id": "lDf9CL_eXrDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ToxicDetector(nn.Module):\n",
        "  def __init__(self, config, vocab_size):\n",
        "    super(ToxicDetector, self).__init__()\n",
        "    self.d_model = config['d_model']\n",
        "    self.seq_len = config['seq_len']\n",
        "    self.num_classes = config['num_classes']\n",
        "    self.depth = config['depth']\n",
        "\n",
        "    # Input Embedding, Positional Embedding\n",
        "    self.emb = InputEmbedding(vocab_size, self.d_model)\n",
        "    self.pe = PositionalEmbedding(self.d_model, self.seq_len)\n",
        "\n",
        "    # Encoder: blocks of encoder blocks\n",
        "    self.Encoder = nn.ModuleList([\n",
        "        EncoderBlock(config) for _ in range(self.depth)\n",
        "    ])\n",
        "    self.Encoder = nn.Sequential(*self.Encoder)\n",
        "    self.mlp = nn.Linear(self.d_model, self.num_classes)\n",
        "\n",
        "  def forward(self, x, mask):\n",
        "    x = self.pe(self.emb(x))\n",
        "\n",
        "    for block in self.Encoder:\n",
        "      x = block(x, mask)\n",
        "    x = x.mean(dim=1)\n",
        "    x = self.mlp(x)\n",
        "    # return x\n",
        "    return torch.log_softmax(x, dim=1)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "68ejCGoUXqH3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking dimension"
      ],
      "metadata": {
        "id": "Xy5wPNUwYvj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d_model = config['d_model']\n",
        "seq_len = config['seq_len']\n",
        "num_classes = config['num_classes']\n",
        "depth = config['depth']\n",
        "\n",
        "# Input Embedding, Positional Embedding\n",
        "emb = InputEmbedding(tokenizer.vocab_size, d_model).to(device)\n",
        "pe = PositionalEmbedding(d_model, seq_len).to(device)\n",
        "\n",
        "# Encoder: blocks of encoder blocks\n",
        "Encoder = nn.ModuleList([\n",
        "    EncoderBlock(config) for _ in range(depth)\n",
        "  ]).to(device)\n",
        "\n",
        "mlp = nn.Linear(d_model, num_classes).to(device)\n",
        "\n",
        "dataiter = iter(train_loader)\n",
        "batch = next(dataiter)\n",
        "\n",
        "encoder_input = batch['encoder_input'].to(device)\n",
        "encoder_mask = batch['encoder_mask'].to(device)\n",
        "target = batch['target'].to(device)\n",
        "\n",
        "x = pe(emb(encoder_input))\n",
        "for block in Encoder:\n",
        "  x = block(x, encoder_mask)\n",
        "print(x.size())\n",
        "x = x.mean(dim=1)\n",
        "print(x.size())\n",
        "x = mlp(x)\n",
        "print(f'after mlp: {x.size()}')\n",
        "print(x.size())\n",
        "print(x)\n",
        "# val, ind = torch.max(x, dim=1)\n",
        "# print(val)\n",
        "# print(ind.to(torch.float32))\n",
        "print(target)\n",
        "ce =nn.CrossEntropyLoss()\n",
        "#bce = nn.BCELoss()\n",
        "print(ce(x, target))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4Am0JJkYtMb",
        "outputId": "75927503-54c3-4af5-e529-deafc8eca5be"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 256, 256])\n",
            "torch.Size([8, 256])\n",
            "after mlp: torch.Size([8, 2])\n",
            "torch.Size([8, 2])\n",
            "tensor([[-0.2417,  0.3399],\n",
            "        [-0.1579,  0.7623],\n",
            "        [ 0.2575, -0.1004],\n",
            "        [-0.0043,  0.3931],\n",
            "        [-0.1640,  0.2150],\n",
            "        [-0.2586,  0.5299],\n",
            "        [-0.3944,  0.2962],\n",
            "        [-0.3240,  0.5139]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "tensor([0, 1, 0, 0, 1, 0, 0, 0], device='cuda:0')\n",
            "tensor(0.8477, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train & Validate TOXIC DETECTOR"
      ],
      "metadata": {
        "id": "17xEirLEVEGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# path for saving model\n",
        "path = \"./ToxicDetector\"\n",
        "pathlib.Path(f\"./{path}/\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# configuration\n",
        "config = get_config(0)\n",
        "print(config)\n",
        "\n",
        "# hyperparameter\n",
        "num_epochs = config['num_epochs']\n",
        "lr = config['lr']\n",
        "\n",
        "# tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(config['checkpoint'])\n",
        "vocab_size = tokenizer.vocab_size\n",
        "\n",
        "# loss, optim, model\n",
        "model = ToxicDetector(config, vocab_size).to(device)\n",
        "ce_loss = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "print(model)\n",
        "\n",
        "Loss = []\n",
        "\n",
        "# TRAINING\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  batch_iterator = tqdm(train_loader, desc = f'Processing epoch {epoch:02d}')\n",
        "  for batch in batch_iterator:\n",
        "    encoder_input = batch['encoder_input'].to(device)\n",
        "    encoder_mask = batch['encoder_mask'].to(device)\n",
        "    target = batch['target'].to(device)\n",
        "\n",
        "    out = model(encoder_input, encoder_mask)\n",
        "    # out = out.squeeze()\n",
        "    # if ids.size()[0] != config['train_batch_size']:\n",
        "    #   out = out.unsqueeze(0)\n",
        "    loss = ce_loss(out, target)\n",
        "    # _, pred = torch.max(out, dim=1)\n",
        "    # pred = pred.to(torch.float32)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    batch_iterator.set_postfix(loss=f\"{loss.item():6.3f}\")\n",
        "    Loss.append(loss.item())\n",
        "  print(f\"{epoch+1}, Loss: {loss.item():.2f}\")\n",
        "  torch.save(model.state_dict(), f'{path}/{epoch}.pth')\n",
        "\n",
        "torch.save(model.state_dict(), f'{path}/td_final_model_2_4_256.pth')\n",
        "\n",
        "# Loss plot\n",
        "plt.plot(Loss, linestyle='-')\n",
        "plt.title('Training loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "preds = []\n",
        "targets = []\n",
        "#validation\n",
        "with torch.no_grad():\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  model.eval()\n",
        "  for idx, batch in enumerate(test_loader, 0):\n",
        "    total += batch['encoder_input'].size()[0]\n",
        "\n",
        "    encoder_input = batch['encoder_input'].to(device)\n",
        "    encoder_mask = batch['encoder_mask'].to(device)\n",
        "    target = batch['target'].to(device)\n",
        "    out = model(encoder_input, encoder_mask)\n",
        "    _, pred = torch.max(out, dim=1)\n",
        "    preds.extend(pred)\n",
        "    targets.extend(target)\n",
        "\n",
        "preds = [p.cpu().numpy() for p in preds]\n",
        "targets = [t.cpu().numpy() for t in targets]\n",
        "\n",
        "print(f\"Precision: {precision_score(preds, targets, average=None)}\")\n",
        "print(f\"Recall: {recall_score(preds, targets, average=None)}\")\n",
        "print(f\"F-1 score: {f1_score(preds, targets, average=None)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y9qgVZZmZ0gQ",
        "outputId": "0d9b77e1-38ef-4c5d-ed31-86022817444d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train_batch_size': 8, 'test_batch_size': 1, 'num_epochs': 30, 'lr': 0.0003, 'seq_len': 256, 'd_model': 256, 'h': 4, 'depth': 2, 'dropout': 0.2, 'num_classes': 2, 'checkpoint': 'bert-base-uncased'}\n",
            "ToxicDetector(\n",
            "  (emb): InputEmbedding(\n",
            "    (embedding): Embedding(30522, 256)\n",
            "  )\n",
            "  (pe): PositionalEmbedding()\n",
            "  (Encoder): Sequential(\n",
            "    (0): EncoderBlock(\n",
            "      (MultiHeadAttention): MultiHeadAttention(\n",
            "        (W_q): Linear(in_features=256, out_features=256, bias=False)\n",
            "        (W_k): Linear(in_features=256, out_features=256, bias=False)\n",
            "        (W_v): Linear(in_features=256, out_features=256, bias=False)\n",
            "        (W_o): Linear(in_features=256, out_features=256, bias=False)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      (FeedForward): FeedForward(\n",
            "        (ffn): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (1): ReLU()\n",
            "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (3): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): EncoderBlock(\n",
            "      (MultiHeadAttention): MultiHeadAttention(\n",
            "        (W_q): Linear(in_features=256, out_features=256, bias=False)\n",
            "        (W_k): Linear(in_features=256, out_features=256, bias=False)\n",
            "        (W_v): Linear(in_features=256, out_features=256, bias=False)\n",
            "        (W_o): Linear(in_features=256, out_features=256, bias=False)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      (FeedForward): FeedForward(\n",
            "        (ffn): Sequential(\n",
            "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
            "          (1): ReLU()\n",
            "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "          (3): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (mlp): Linear(in_features=256, out_features=2, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 00: 100%|██████████| 3168/3168 [01:31<00:00, 34.59it/s, loss=0.316]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1, Loss: 0.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 01: 100%|██████████| 3168/3168 [01:31<00:00, 34.60it/s, loss=0.057]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2, Loss: 0.06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 02: 100%|██████████| 3168/3168 [01:31<00:00, 34.54it/s, loss=0.049]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3, Loss: 0.05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 03: 100%|██████████| 3168/3168 [01:31<00:00, 34.77it/s, loss=0.005]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4, Loss: 0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 04: 100%|██████████| 3168/3168 [01:32<00:00, 34.36it/s, loss=0.030]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5, Loss: 0.03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 05: 100%|██████████| 3168/3168 [01:31<00:00, 34.65it/s, loss=0.081]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6, Loss: 0.08\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 06: 100%|██████████| 3168/3168 [01:31<00:00, 34.49it/s, loss=0.362]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7, Loss: 0.36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 07: 100%|██████████| 3168/3168 [01:31<00:00, 34.53it/s, loss=0.001]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8, Loss: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 08: 100%|██████████| 3168/3168 [01:32<00:00, 34.35it/s, loss=0.004]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9, Loss: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 09: 100%|██████████| 3168/3168 [01:31<00:00, 34.58it/s, loss=0.160]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10, Loss: 0.16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 10: 100%|██████████| 3168/3168 [01:31<00:00, 34.52it/s, loss=0.014]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11, Loss: 0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 11: 100%|██████████| 3168/3168 [01:31<00:00, 34.53it/s, loss=0.165]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12, Loss: 0.16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 12: 100%|██████████| 3168/3168 [01:32<00:00, 34.39it/s, loss=0.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13, Loss: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 13: 100%|██████████| 3168/3168 [01:31<00:00, 34.53it/s, loss=0.006]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14, Loss: 0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 14: 100%|██████████| 3168/3168 [01:32<00:00, 34.38it/s, loss=0.012]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15, Loss: 0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 15: 100%|██████████| 3168/3168 [01:31<00:00, 34.57it/s, loss=0.045]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16, Loss: 0.05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 16: 100%|██████████| 3168/3168 [01:32<00:00, 34.42it/s, loss=0.006]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17, Loss: 0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 17: 100%|██████████| 3168/3168 [01:32<00:00, 34.37it/s, loss=0.044]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18, Loss: 0.04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 18: 100%|██████████| 3168/3168 [01:31<00:00, 34.54it/s, loss=0.023]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19, Loss: 0.02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 19: 100%|██████████| 3168/3168 [01:31<00:00, 34.55it/s, loss=0.003]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20, Loss: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 20: 100%|██████████| 3168/3168 [01:32<00:00, 34.41it/s, loss=0.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21, Loss: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 21: 100%|██████████| 3168/3168 [01:32<00:00, 34.40it/s, loss=0.009]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22, Loss: 0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 22: 100%|██████████| 3168/3168 [01:32<00:00, 34.26it/s, loss=0.003]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23, Loss: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 23: 100%|██████████| 3168/3168 [01:31<00:00, 34.67it/s, loss=0.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24, Loss: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 24: 100%|██████████| 3168/3168 [01:32<00:00, 34.34it/s, loss=0.002]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25, Loss: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 25: 100%|██████████| 3168/3168 [01:31<00:00, 34.44it/s, loss=0.003]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26, Loss: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 26: 100%|██████████| 3168/3168 [01:32<00:00, 34.33it/s, loss=0.000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27, Loss: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 27: 100%|██████████| 3168/3168 [01:31<00:00, 34.78it/s, loss=0.001]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28, Loss: 0.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 28: 100%|██████████| 3168/3168 [01:32<00:00, 34.28it/s, loss=0.068]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29, Loss: 0.07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing epoch 29: 100%|██████████| 3168/3168 [01:31<00:00, 34.70it/s, loss=0.004]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30, Loss: 0.00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: [0.9692029  0.82708333]\n",
            "Recall: [0.92801388 0.92111369]\n",
            "F-1 score: [0.94816128 0.8715697 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TEST"
      ],
      "metadata": {
        "id": "2OScRA8fVMl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(test_loader)"
      ],
      "metadata": {
        "id": "9hXZzn8x8fxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for a in range(100):\n",
        "  batch = next(dataiter)\n",
        "\n",
        "  txts = batch['txt']\n",
        "  encoder_input = batch['encoder_input'].to(device)\n",
        "  encoder_mask = batch['encoder_mask'].to(device)\n",
        "  target = batch['target'].to(device)\n",
        "  out = model(encoder_input, encoder_mask)\n",
        "\n",
        "  _, pred = torch.max(out, dim=1)\n",
        "\n",
        "  for i in range(len(txts)):\n",
        "    print(f\"Predicted: {pred[i]}\")\n",
        "    print(f\"Target: {target[i]}\")\n",
        "    print('\\n')\n",
        "\n"
      ],
      "metadata": {
        "id": "2f-Z4cDOtZXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Leaves a comment.\n",
        "\n",
        "comment = \"are you kidding me?\" #@param {type: \"string\"}\n",
        "\n",
        "h = config['h']\n",
        "seq_len = config['seq_len']\n",
        "\n",
        "tokenized_source = tokenizer(comment, max_length = seq_len, padding='max_length', truncation=True, return_tensors='pt').to(device)\n",
        "encoder_input = tokenized_source['input_ids']\n",
        "\n",
        "encoder_mask = torch.tensor(tokenized_source['attention_mask'], dtype= torch.long).unsqueeze(0)\n",
        "encoder_mask = encoder_mask.repeat(1, h, 1)\n",
        "encoder_mask = encoder_mask.expand(seq_len, h, seq_len)\n",
        "encoder_mask = encoder_mask.transpose(0,1).contiguous()\n",
        "\n",
        "\n",
        "out = model(encoder_input, encoder_mask)\n",
        "_, pred = torch.max(out, dim=1)\n",
        "print(pred)\n",
        "\n",
        "h = config['h']\n",
        "seq_len = config['seq_len']\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "EY0SQwzU15mb",
        "outputId": "e8ea3e45-6382-4a13-d84f-8eac82fa7d76"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z6uUuFZZ0IFl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}